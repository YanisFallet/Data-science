Cette annÃ©e, en maths expertes, nous avons abordÃ© les matrices ğŸ§® ce qui m'a fait grandement progresser dans l'uilisation de numpy.
Ainsi, avec du travail, j'ai rÃ©ussi Ã  coder des rÃ©gressions linÃ©raires, polynomiales et Ã  variables multiples. 

Le principe est globalement le mÃªme. Nous disposons d'un dataset avec une ou plusieurs features. 
On introduit un vecteur thÃªta qui dÃ©finit notre premier modÃ¨le.
Par la suite, on calcule l'erreur quadratique moyenne de notre modÃ¨le avec la fonction coÃ»t puis on applique une descente de gradient.

Ainsi, on obtient un vecteur thÃªta final qui nous donne les meilleurs paramÃ¨tres de notre modÃ¨le minimisant l'erreur entre le modÃ¨le et les donnÃ©es.
